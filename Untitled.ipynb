{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin \n",
    "import requests\n",
    "import re\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait as wait\n",
    "\n",
    "# Download IMDB's Top 250 data\n",
    "url = 'http://www.imdb.com/chart/top'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "movies = soup.select('td.titleColumn')\n",
    "links = [a.attrs.get('href') for a in soup.select('td.titleColumn a')]\n",
    "crew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\n",
    "ratings = [b.attrs.get('data-value') for b in soup.select('td.posterColumn span[name=ir]')]\n",
    "votes = [b.attrs.get('data-value') for b in soup.select('td.ratingColumn strong')]\n",
    "\n",
    "imdb = []\n",
    "dataset = []\n",
    "# Store each item into dictionary (data), then put those into a list (imdb)\n",
    "for index in range(0, 2):\n",
    "    # Seperate movie into: 'place', 'title', 'year'\n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    movie_title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    place = movie[:len(str(index))-(len(movie))]\n",
    "    data = {\"movie_title\": movie_title,\n",
    "#            \"year\": year,\n",
    "#             \"place\": place,\n",
    "#             \"star_cast\": crew[index],\n",
    "            \"rating\": ratings[index],\n",
    "#             \"vote\": votes[index],\n",
    "            \"link\": links[index]}\n",
    "    imdb.append(data)\n",
    "\n",
    "for item in imdb:\n",
    "    #print(item['place'], '-', item['movie_title'], '('+item['year']+') -', 'Starring:', item['star_cast'],  item['link'])\n",
    "    url =  'http://www.imdb.com'+ item['link'][:17]+'reviews'\n",
    "    driver = webdriver.Chrome('/home/dev/Downloads/chromedriver_linux64/chromedriver')\n",
    "    driver.get(url)\n",
    "\n",
    "    labtn = driver.find_element_by_id('load-more-trigger')\n",
    "    labtn.click()\n",
    "\n",
    "    wait(driver, 15).until(lambda x: len(driver.find_elements_by_css_selector(\"div.lister-item-content\")) > 39)\n",
    "    source_code = driver.page_source\n",
    "    soup = BeautifulSoup(source_code, 'lxml')\n",
    "    containers=soup.find_all('div', class_ = 'lister-item-content')\n",
    "    reviews = []\n",
    "    for container in containers:\n",
    "        if container.find('a', class_ = 'title' ) is not None:\n",
    "            title = container.a.text.strip()\n",
    "            bar = container.find('div', class_ = 'ipl-ratings-bar')\n",
    "            if bar is None:\n",
    "                continue\n",
    "            else:\n",
    "                rating = bar.text.strip()  \n",
    "                content_cont = container.find('div', class_ = 'text show-more__control')\n",
    "                if content_cont is not None:\n",
    "                    content = content_cont.text.strip()\n",
    "                else:\n",
    "                    content_cont = container.find('div', class_ = 'text show-more__control clickable')\n",
    "                    content = content_cont.text.strip()\n",
    "                content = title+content\n",
    "                data2 = {\n",
    "                    \"user_rating\": rating,\n",
    "                    \"content\" : content  \n",
    "                }\n",
    "                reviews.append(data2)\n",
    "    \n",
    "    movies = {\n",
    "        \"title\" : item['movie_title'],\n",
    "        \"rating\" : item['rating'],\n",
    "        \"reviews\": reviews\n",
    "    }\n",
    "    dataset.append(movies) \n",
    "    #print(movies)           \n",
    "    driver.quit()\n",
    "    \n",
    "#print(dataset)\n",
    "# df=pd.DataFrame(dataset)\n",
    "# print(df)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "                      title    rating  \\\n",
      "0  The Shawshank Redemption  9.217021   \n",
      "1             The Godfather  9.155527   \n",
      "2            Disaster Movie  1.997981   \n",
      "3  Manos: The Hands of Fate  2.051327   \n",
      "\n",
      "                                             reviews  \n",
      "0  [{'user_rating': '10/10', 'content': 'Tied for...  \n",
      "1  [{'user_rating': '10/10', 'content': \"For Me, ...  \n",
      "2  [{'user_rating': '1/10', 'content': 'The fact ...  \n",
      "3  [{'user_rating': '1/10', 'content': 'Your eyes...  \n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.imdb.com/chart/bottom'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "movies = soup.select('td.titleColumn')\n",
    "links = [a.attrs.get('href') for a in soup.select('td.titleColumn a')]\n",
    "crew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\n",
    "ratings = [b.attrs.get('data-value') for b in soup.select('td.posterColumn span[name=ir]')]\n",
    "votes = [b.attrs.get('data-value') for b in soup.select('td.ratingColumn strong')]\n",
    "\n",
    "imdb = []\n",
    "# Store each item into dictionary (data), then put those into a list (imdb)\n",
    "for index in range(0, 2):\n",
    "    # Seperate movie into: 'place', 'title', 'year'\n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    movie_title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    place = movie[:len(str(index))-(len(movie))]\n",
    "    data = {\"movie_title\": movie_title,\n",
    "#            \"year\": year,\n",
    "#             \"place\": place,\n",
    "#             \"star_cast\": crew[index],\n",
    "            \"rating\": ratings[index],\n",
    "#             \"vote\": votes[index],\n",
    "            \"link\": links[index]}\n",
    "    imdb.append(data)\n",
    "\n",
    "for item in imdb:\n",
    "    #print(item['place'], '-', item['movie_title'], '('+item['year']+') -', 'Starring:', item['star_cast'],  item['link'])\n",
    "    url =  'http://www.imdb.com'+ item['link'][:17]+'reviews'\n",
    "    driver = webdriver.Chrome('/home/dev/Downloads/chromedriver_linux64/chromedriver')\n",
    "    driver.get(url)\n",
    "\n",
    "    labtn = driver.find_element_by_id('load-more-trigger')\n",
    "    labtn.click()\n",
    "\n",
    "    wait(driver, 15).until(lambda x: len(driver.find_elements_by_css_selector(\"div.lister-item-content\")) > 39)\n",
    "    source_code = driver.page_source\n",
    "    soup = BeautifulSoup(source_code, 'lxml')\n",
    "    containers=soup.find_all('div', class_ = 'lister-item-content')\n",
    "    reviews = []\n",
    "    for container in containers:\n",
    "        if container.find('a', class_ = 'title' ) is not None:\n",
    "            title = container.a.text.strip()\n",
    "            bar = container.find('div', class_ = 'ipl-ratings-bar')\n",
    "            if bar is None:\n",
    "                continue\n",
    "            else:\n",
    "                rating = bar.text.strip()  \n",
    "                content_cont = container.find('div', class_ = 'text show-more__control')\n",
    "                if content_cont is not None:\n",
    "                    content = content_cont.text.strip()\n",
    "                else:\n",
    "                    content_cont = container.find('div', class_ = 'text show-more__control clickable')\n",
    "                    content = content_cont.text.strip()\n",
    "                content = title+content\n",
    "                data2 = {\n",
    "                    \"user_rating\": rating,\n",
    "                    \"content\" : content  \n",
    "                }\n",
    "                reviews.append(data2)\n",
    "    \n",
    "    movies = {\n",
    "        \"title\" : item['movie_title'],\n",
    "        \"rating\" : item['rating'],\n",
    "        \"reviews\": reviews\n",
    "    }\n",
    "    dataset.append(movies) \n",
    "    #print(movies)           \n",
    "    driver.quit()\n",
    "print(len(dataset))\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      title    rating  \\\n",
      "0  The Shawshank Redemption  9.217021   \n",
      "1             The Godfather  9.155527   \n",
      "2            Disaster Movie  1.997981   \n",
      "3  Manos: The Hands of Fate  2.051327   \n",
      "4    Avengers: Infinity War  8.500000   \n",
      "5                   Aquaman  7.300000   \n",
      "\n",
      "                                             reviews  \n",
      "0  [{'user_rating': '10/10', 'content': 'Tied for...  \n",
      "1  [{'user_rating': '10/10', 'content': \"For Me, ...  \n",
      "2  [{'user_rating': '1/10', 'content': 'The fact ...  \n",
      "3  [{'user_rating': '1/10', 'content': 'Your eyes...  \n",
      "4  [{'user_rating': '10/10', 'content': 'Unlike a...  \n",
      "5  [{'user_rating': '6/10', 'content': \"Is it jus...  \n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Download IMDB's Top 250 data\n",
    "url = 'https://www.imdb.com/list/ls058813655/?sort=list_order,asc&st_dt=&mode=simple&page=1&ref_=ttls_vw_smp'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "# movies = soup.select('td.titleColumn')\n",
    "# links = [a.attrs.get('href') for a in soup.select('td.titleColumn a')]\n",
    "# crew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\n",
    "# ratings = [b.attrs.get('data-value') for b in soup.select('td.posterColumn span[name=ir]')]\n",
    "# votes = [b.attrs.get('data-value') for b in soup.select('td.ratingColumn strong')]\n",
    "\n",
    "movies = soup.find_all('div',class_='lister-col-wrapper')\n",
    "\n",
    "imdb = []\n",
    "# Store each item into dictionary (data), then put those into a list (imdb)\n",
    "for index in range(0, 2):\n",
    "    # Seperate movie into: 'place', 'title', 'year'\n",
    "#     movie_string = movies[index].get_text()\n",
    "#     movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "#     movie_title = movie[len(str(index))+1:-7]\n",
    "    movie_title = movies[index].a.text\n",
    "    rating_temp = movies[index].find('div',class_='col-imdb-rating')\n",
    "    rating = rating_temp.strong.text.strip()\n",
    "    link=movies[index].a.attrs.get('href')\n",
    "#     year = re.search('(.*?)(.âˆ—?)', movie_string).group(1)\n",
    "#     place = movie[:len(str(index))-(len(movie))]\n",
    "    data = {\"movie_title\": movie_title,\n",
    "#             \"year\": year,\n",
    "#             \"place\": place,\n",
    "#             \"star_cast\": crew[index],\n",
    "            \"rating\": rating,\n",
    "#             \"vote\": votes[index],\n",
    "            \"link\": link}\n",
    "    imdb.append(data)\n",
    "\n",
    "for item in imdb:\n",
    "    #print(item['place'], '-', item['movie_title'], '('+item['year']+') -', 'Starring:', item['star_cast'],  item['link'])\n",
    "    url =  'http://www.imdb.com'+ item['link'][:17]+'reviews'\n",
    "    driver = webdriver.Chrome('/home/dev/Downloads/chromedriver_linux64/chromedriver')\n",
    "   # driver = webdriver.Chrome('/home/udbhav/Downloads/chromedriver')\n",
    "    driver.get(url)\n",
    "\n",
    "    labtn = driver.find_element_by_id('load-more-trigger')\n",
    "    labtn.click()\n",
    "\n",
    "    wait(driver, 15).until(lambda x: len(driver.find_elements_by_css_selector(\"div.lister-item-content\")) > 39)\n",
    "    source_code = driver.page_source\n",
    "    soup = BeautifulSoup(source_code, 'lxml')\n",
    "    containers=soup.find_all('div', class_ = 'lister-item-content')\n",
    "    reviews = []\n",
    "    for container in containers:\n",
    "        if container.find('a', class_ = 'title' ) is not None:\n",
    "            title = container.a.text.strip()\n",
    "            bar = container.find('div', class_ = 'ipl-ratings-bar')\n",
    "            if bar is None:\n",
    "                continue\n",
    "            else:\n",
    "                rating = bar.text.strip()  \n",
    "                content_cont = container.find('div', class_ = 'text show-more__control')\n",
    "                if content_cont is not None:\n",
    "                    content = content_cont.text.strip()\n",
    "                else:\n",
    "                    content_cont = container.find('div', class_ = 'text show-more__control clickable')\n",
    "                    content = content_cont.text.strip()\n",
    "                content = title+content\n",
    "                data2 = {\n",
    "                    \"user_rating\": rating,\n",
    "                    \"content\" : content  \n",
    "                }\n",
    "                reviews.append(data2)\n",
    "    \n",
    "    movies = {\n",
    "        \"title\" : item['movie_title'],\n",
    "        \"rating\" : item['rating'],\n",
    "        \"reviews\": reviews\n",
    "    }\n",
    "    dataset.append(movies) \n",
    "    #print(movies)           \n",
    "    driver.quit()\n",
    "    \n",
    "#print(dataset)\n",
    "f = open(\"sample.csv\", \"w\")\n",
    "writer = csv.DictWriter(\n",
    "    f, fieldnames=[\"title\", \"rating\", \"reviews\"])\n",
    "writer.writeheader()\n",
    "writer.writerows(dataset)\n",
    "f.close()\n",
    "df = pd.read_csv('sample.csv')\n",
    "print(df)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
