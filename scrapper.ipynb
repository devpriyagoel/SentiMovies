{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin \n",
    "import requests\n",
    "import re\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait as wait\n",
    "\n",
    "# Download IMDB's Top 250 data\n",
    "url = 'http://www.imdb.com/chart/top'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "movies = soup.select('td.titleColumn')\n",
    "links = [a.attrs.get('href') for a in soup.select('td.titleColumn a')]\n",
    "crew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\n",
    "ratings = [b.attrs.get('data-value') for b in soup.select('td.posterColumn span[name=ir]')]\n",
    "votes = [b.attrs.get('data-value') for b in soup.select('td.ratingColumn strong')]\n",
    "\n",
    "imdb = []\n",
    "dataset = []\n",
    "# Store each item into dictionary (data), then put those into a list (imdb)\n",
    "for index in range(0, 1):\n",
    "    # Seperate movie into: 'place', 'title', 'year'\n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    movie_title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    place = movie[:len(str(index))-(len(movie))]\n",
    "    data = {\"movie_title\": movie_title,\n",
    "#            \"year\": year,\n",
    "#             \"place\": place,\n",
    "#             \"star_cast\": crew[index],\n",
    "            \"rating\": ratings[index],\n",
    "#             \"vote\": votes[index],\n",
    "            \"link\": links[index]}\n",
    "    imdb.append(data)\n",
    "\n",
    "for item in imdb:\n",
    "    #print(item['place'], '-', item['movie_title'], '('+item['year']+') -', 'Starring:', item['star_cast'],  item['link'])\n",
    "    url =  'http://www.imdb.com'+ item['link'][:17]+'reviews'\n",
    "    driver = webdriver.Chrome('/home/dev/Downloads/chromedriver_linux64/chromedriver')\n",
    "    driver.get(url)\n",
    "\n",
    "    labtn = driver.find_element_by_id('load-more-trigger')\n",
    "    labtn.click()\n",
    "\n",
    "    wait(driver, 15).until(lambda x: len(driver.find_elements_by_css_selector(\"div.lister-item-content\")) > 39)\n",
    "    source_code = driver.page_source\n",
    "    soup = BeautifulSoup(source_code, 'lxml')\n",
    "    containers=soup.find_all('div', class_ = 'lister-item-content')\n",
    "    \n",
    "    \n",
    "    reviews = []\n",
    "    user_ratings=[]\n",
    "    for container in containers:\n",
    "        if container.find('a', class_ = 'title' ) is not None:\n",
    "            title = container.a.text.strip()\n",
    "            \n",
    "            bar = container.find('div', class_ = 'ipl-ratings-bar')\n",
    "            if bar is None:\n",
    "                continue\n",
    "            else:\n",
    "                rating = bar.text.strip()  \n",
    "                content_cont = container.find('div', class_ = 'text show-more__control')\n",
    "                if content_cont is not None:\n",
    "                    content = content_cont.text.strip()\n",
    "                    #content=' '.join(re.split(r'\\t+',content))\n",
    "                    #print(content)\n",
    "                else:\n",
    "                    content_cont = container.find('div', class_ = 'text show-more__control clickable')\n",
    "                    content = content_cont.text.strip()\n",
    "                content = title+' '+content\n",
    "                content=' '.join(re.split(r'\\t+',content))\n",
    "                reviews.append(content)\n",
    "                user_ratings.append(rating)\n",
    "    \n",
    "   \n",
    "    #print(movies) \n",
    "    driver.quit()\n",
    "    url1 =  'http://www.imdb.com'+ item['link'][:17]+'plotsummary'\n",
    "    #print(url1)\n",
    "    response = requests.get(url1)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    containers=soup.find_all('ul', {'id':'plot-synopsis-content'})\n",
    "    synopsis=\"\"\n",
    "    for temp in containers:\n",
    "        for temp1 in temp.find_all('li'):\n",
    "            synopsis=temp1.text.strip()\n",
    "            #print(synopsis)\n",
    "    movies = {\n",
    "        \"title\" : item['movie_title'],\n",
    "        \"rating\" : item['rating'],\n",
    "        \"reviews\": reviews,\n",
    "        \"user_ratings\":user_ratings,\n",
    "        \"synopsis\":synopsis\n",
    "    }\n",
    "    dataset.append(movies)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/chart/bottom'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "movies = soup.select('td.titleColumn')\n",
    "links = [a.attrs.get('href') for a in soup.select('td.titleColumn a')]\n",
    "crew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\n",
    "ratings = [b.attrs.get('data-value') for b in soup.select('td.posterColumn span[name=ir]')]\n",
    "votes = [b.attrs.get('data-value') for b in soup.select('td.ratingColumn strong')]\n",
    "\n",
    "imdb = []\n",
    "# Store each item into dictionary (data), then put those into a list (imdb)\n",
    "for index in range(0, 1):\n",
    "    # Seperate movie into: 'place', 'title', 'year'\n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    movie_title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    place = movie[:len(str(index))-(len(movie))]\n",
    "    data = {\"movie_title\": movie_title,\n",
    "#            \"year\": year,\n",
    "#             \"place\": place,\n",
    "#             \"star_cast\": crew[index],\n",
    "            \"rating\": ratings[index],\n",
    "#             \"vote\": votes[index],\n",
    "            \"link\": links[index]}\n",
    "    imdb.append(data)\n",
    "\n",
    "for item in imdb:\n",
    "    #print(item['place'], '-', item['movie_title'], '('+item['year']+') -', 'Starring:', item['star_cast'],  item['link'])\n",
    "    url =  'http://www.imdb.com'+ item['link'][:17]+'reviews'\n",
    "    driver = webdriver.Chrome('/home/dev/Downloads/chromedriver_linux64/chromedriver')\n",
    "    driver.get(url)\n",
    "\n",
    "    labtn = driver.find_element_by_id('load-more-trigger')\n",
    "    labtn.click()\n",
    "\n",
    "    wait(driver, 15).until(lambda x: len(driver.find_elements_by_css_selector(\"div.lister-item-content\")) > 39)\n",
    "    source_code = driver.page_source\n",
    "    soup = BeautifulSoup(source_code, 'lxml')\n",
    "    containers=soup.find_all('div', class_ = 'lister-item-content')\n",
    "   \n",
    "    reviews = []\n",
    "    user_ratings=[]\n",
    "    for container in containers:\n",
    "        if container.find('a', class_ = 'title' ) is not None:\n",
    "            title = container.a.text.strip()\n",
    "            title=' '.join(re.split(r'\\t+',title))\n",
    "            bar = container.find('div', class_ = 'ipl-ratings-bar')\n",
    "            if bar is None:\n",
    "                continue\n",
    "            else:\n",
    "                rating = bar.text.strip()  \n",
    "                content_cont = container.find('div', class_ = 'text show-more__control')\n",
    "                if content_cont is not None:\n",
    "                    content = content_cont.text.strip()\n",
    "                    content=' '.join(re.split(r'\\t+',content))\n",
    "                else:\n",
    "                    content_cont = container.find('div', class_ = 'text show-more__control clickable')\n",
    "                    content = content_cont.text.strip()\n",
    "                content = title+' '+content\n",
    "                reviews.append(content)\n",
    "                user_ratings.append(rating)\n",
    "    \n",
    "   \n",
    "    #print(movies) \n",
    "    driver.quit()\n",
    "    url1 =  'http://www.imdb.com'+ item['link'][:17]+'plotsummary'\n",
    "    response = requests.get(url1)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    containers=soup.find_all('ul', {'id':'plot-synopsis-content'})\n",
    "    synopsis=\"\"\n",
    "    for temp in containers:\n",
    "        for temp1 in temp.find_all('li'):\n",
    "            synopsis=temp1.text.strip()\n",
    "            #print(synopsis)\n",
    "    movies = {\n",
    "        \"title\" : item['movie_title'],\n",
    "        \"rating\" : item['rating'],\n",
    "        \"reviews\": reviews,\n",
    "        \"user_ratings\":user_ratings,\n",
    "        \"synopsis\":synopsis\n",
    "    }\n",
    "    dataset.append(movies)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               rating                                            reviews  \\\n",
      "0   9.217045300620226  [Tied for the best movie I have ever seen Why ...   \n",
      "1  1.9975821404178076  [The fact that aspiring actors, directors, and...   \n",
      "2                 8.5  [Unlike anything ever done in the history of c...   \n",
      "\n",
      "                                            synopsis  \\\n",
      "0  In 1947, Andy Dufresne (Tim Robbins), a banker...   \n",
      "1  The movie opens with spoofing \"Armageddon\" and...   \n",
      "2  SPOILER: Thanos and his Children - Proxima Mid...   \n",
      "\n",
      "                      title                                       user_ratings  \n",
      "0  The Shawshank Redemption  [10/10, 10/10, 10/10, 10/10, 10/10, 10/10, 10/...  \n",
      "1            Disaster Movie  [1/10, 1/10, 1/10, 1/10, 1/10, 1/10, 1/10, 1/1...  \n",
      "2    Avengers: Infinity War  [10/10, 10/10, 10/10, 9/10, 10/10, 10/10, 10/1...  \n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.imdb.com/list/ls058813655/?sort=list_order,asc&st_dt=&mode=simple&page=1&ref_=ttls_vw_smp'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "# movies = soup.select('td.titleColumn')\n",
    "# links = [a.attrs.get('href') for a in soup.select('td.titleColumn a')]\n",
    "# crew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\n",
    "# ratings = [b.attrs.get('data-value') for b in soup.select('td.posterColumn span[name=ir]')]\n",
    "# votes = [b.attrs.get('data-value') for b in soup.select('td.ratingColumn strong')]\n",
    "\n",
    "movies = soup.find_all('div',class_='lister-col-wrapper')\n",
    "\n",
    "imdb = []\n",
    "# Store each item into dictionary (data), then put those into a list (imdb)\n",
    "for index in range(0, 1):\n",
    "    # Seperate movie into: 'place', 'title', 'year'\n",
    "#     movie_string = movies[index].get_text()\n",
    "#     movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "#     movie_title = movie[len(str(index))+1:-7]\n",
    "    movie_title = movies[index].a.text\n",
    "    rating_temp = movies[index].find('div',class_='col-imdb-rating')\n",
    "    rating = rating_temp.strong.text.strip()\n",
    "    link=movies[index].a.attrs.get('href')\n",
    "#     year = re.search('(.*?)(.âˆ—?)', movie_string).group(1)\n",
    "#     place = movie[:len(str(index))-(len(movie))]\n",
    "    data = {\"movie_title\": movie_title,\n",
    "#             \"year\": year,\n",
    "#             \"place\": place,\n",
    "#             \"star_cast\": crew[index],\n",
    "            \"rating\": rating,\n",
    "#             \"vote\": votes[index],\n",
    "            \"link\": link}\n",
    "    imdb.append(data)\n",
    "\n",
    "for item in imdb:\n",
    "    #print(item['place'], '-', item['movie_title'], '('+item['year']+') -', 'Starring:', item['star_cast'],  item['link'])\n",
    "    url =  'http://www.imdb.com'+ item['link'][:17]+'reviews'\n",
    "    driver = webdriver.Chrome('/home/dev/Downloads/chromedriver_linux64/chromedriver')\n",
    "   # driver = webdriver.Chrome('/home/udbhav/Downloads/chromedriver')\n",
    "    driver.get(url)\n",
    "\n",
    "    labtn = driver.find_element_by_id('load-more-trigger')\n",
    "    labtn.click()\n",
    "\n",
    "    wait(driver, 15).until(lambda x: len(driver.find_elements_by_css_selector(\"div.lister-item-content\")) > 39)\n",
    "    source_code = driver.page_source\n",
    "    soup = BeautifulSoup(source_code, 'lxml')\n",
    "    containers=soup.find_all('div', class_ = 'lister-item-content')\n",
    "    reviews = []\n",
    "    user_ratings=[]\n",
    "    for container in containers:\n",
    "        if container.find('a', class_ = 'title' ) is not None:\n",
    "            title = container.a.text.strip()\n",
    "            title=' '.join(re.split(r'\\t+',title))\n",
    "            bar = container.find('div', class_ = 'ipl-ratings-bar')\n",
    "            if bar is None:\n",
    "                continue\n",
    "            else:\n",
    "                rating = bar.text.strip()  \n",
    "                content_cont = container.find('div', class_ = 'text show-more__control')\n",
    "                if content_cont is not None:\n",
    "                    content = content_cont.text.strip()\n",
    "                    content=' '.join(re.split(r'\\t+',content))\n",
    "                else:\n",
    "                    content_cont = container.find('div', class_ = 'text show-more__control clickable')\n",
    "                    content = content_cont.text.strip()\n",
    "                content = title+' '+content\n",
    "                reviews.append(content)\n",
    "                user_ratings.append(rating)\n",
    "    \n",
    "   \n",
    "    #print(movies) \n",
    "    driver.quit()\n",
    "    url1 =  'http://www.imdb.com'+ item['link'][:17]+'plotsummary'\n",
    "    response = requests.get(url1)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    containers=soup.find_all('ul', {'id':'plot-synopsis-content'})\n",
    "    synopsis=\"\"\n",
    "    for temp in containers:\n",
    "        for temp1 in temp.find_all('li'):\n",
    "            synopsis=temp1.text.strip()\n",
    "            #print(synopsis)\n",
    "    movies = {\n",
    "        \"title\" : item['movie_title'],\n",
    "        \"rating\" : item['rating'],\n",
    "        \"reviews\": reviews,\n",
    "        \"user_ratings\":user_ratings,\n",
    "        \"synopsis\":synopsis\n",
    "    }\n",
    "    dataset.append(movies)\n",
    "    \n",
    "df=pd.DataFrame(dataset)\n",
    "#print(dataset)\n",
    "# f = open(\"sample1.tsv\", \"w\")\n",
    "# writer = csv.DictWriter(\n",
    "#     f, fieldnames=[\"title\", \"rating\", \"reviews\",\"user_ratings\",\"synopsis\"])\n",
    "# writer.writeheader()\n",
    "# writer.writerows(dataset)\n",
    "# f.close()\n",
    "# df = pd.read_csv('sample1.tsv')\n",
    "df.to_csv('sample1.tsv',sep='\\t')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
