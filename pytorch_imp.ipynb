{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 164,
>>>>>>> 3212855949671293fb171a9610f3f23730018b67
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 165,
>>>>>>> 3212855949671293fb171a9610f3f23730018b67
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
>>>>>>> 3212855949671293fb171a9610f3f23730018b67
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(df,max_len_synopsis):\n",
    "    fin_text=df.iloc[0]['synopsis']\n",
    "    max_len_synopsis = max(max_len_synopsis, len(fin_text))\n",
    "    chars_temp = set(fin_text)\n",
    "    #chars.union(chars_temp)\n",
    "    for review in df.iloc[0]['reviews']:\n",
    "        chars_temp=chars_temp.union(set(review))\n",
    "    return chars_temp,max_len_synopsis"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 167,
>>>>>>> 3212855949671293fb171a9610f3f23730018b67
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 168,
>>>>>>> 3212855949671293fb171a9610f3f23730018b67
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 1\n",
    "fin_text=\"\"\n",
    "chars = set(fin_text)\n",
    "max_len_synop=0\n",
    "for chunk in pd.read_csv('preprocessed.tsv', chunksize=chunksize, delimiter='\\t'):\n",
    "    df= pd.DataFrame(chunk)\n",
    "    df['reviews'] = df['reviews'].apply(literal_eval)\n",
    "    temp=func(df,max_len_synop)\n",
    "    chars = chars.union(temp[0])\n",
    "    max_len_synop=max(max_len_synop,temp[1])\n",
    "chars_tuple = tuple(chars)\n",
    "int2char = dict(enumerate(chars_tuple))\n",
    "char2int = {ch: ii for ii, ch in int2char.items()}"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 169,
>>>>>>> 3212855949671293fb171a9610f3f23730018b67
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "{'o', '8', 'l', 'i', 'P', 'T', 'x', 'w', 'D', 'z', ']', \"'\", 'W', 'F', 'A', '`', 'H', 'L', 'C', 'y', 'm', '?', '5', 'h', '*', 'J', 'é', 'r', '#', 'c', ' ', 'n', 'q', '=', 'g', '(', 'ê', '/', 'Q', 'I', 'K', '[', 'e', 'U', ':', '.', 'u', 'j', 'E', '6', ',', 'G', '+', '%', '1', '7', 'f', '-', ';', '\\x96', 'S', '4', '0', 'Y', 'R', '9', 'v', 'a', 't', 'p', '3', 'V', 'M', ')', '$', '\"', 's', '!', 'd', '\\n', 'k', '2', 'N', 'O', 'b', 'B', 'Z', '&', 'X', '~'}\n",
=======
      "{'=', '7', 'r', 'Q', '(', 'Y', '5', '?', '`', 'P', 'l', 'j', '-', '!', 'o', '[', 'p', 'a', ',', 'y', '+', '#', 'z', '&', 'U', 'x', 'X', '.', '9', 'q', 'ê', 'R', ';', ':', 'n', 'I', 'H', 'B', 'g', 'O', '8', 'L', 'K', 'F', '1', '$', ')', '\\n', '0', '%', 'G', 'W', 'b', 'k', 'v', 'c', '3', '4', 'M', 'E', 'D', '/', 'e', 'A', '\"', 'T', 'u', '*', '2', '6', 'f', 'V', 's', '~', ' ', 'Z', 'C', 'h', 'J', 't', 'é', 'N', 'w', \"'\", 'i', ']', 'S', 'd', 'm', '\\x96'}\n",
>>>>>>> 3212855949671293fb171a9610f3f23730018b67
      "11801\n"
     ]
    }
   ],
   "source": [
    "print(chars)\n",
    "print(max_len_synop)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 170,
>>>>>>> 3212855949671293fb171a9610f3f23730018b67
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.read_csv('preprocessed.tsv',delimiter='\\t', nrows=3)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 171,
>>>>>>> 3212855949671293fb171a9610f3f23730018b67
   "metadata": {},
   "outputs": [],
   "source": [
    "len_of_review = len(df.iloc[0]['reviews'][0])\n",
    "fortyforty = (int)((len_of_review -35)/5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_len_synopsis=0\n",
    "# max_len_reviews=0 \n",
    "# no_of_reviews=0\n",
    "# tot_no_of_reviews=0\n",
    "# fin_text=''\n",
    "# for index,row in df.iterrows():\n",
    "#     max_len_synopsis = max(max_len_synopsis, len(row['synopsis']))\n",
    "#     text=''.join(row['synopsis'])\n",
    "#     fin_text+=' '+text\n",
    "# for i in range(0, len(df)):\n",
    "#     temp = df.iloc[i]['reviews']\n",
    "#     no_of_reviews=0;\n",
    "#     for text in temp:\n",
    "#         max_len_reviews = max(max_len_reviews, len(text))\n",
    "#         no_of_reviews=no_of_reviews+1\n",
    "#         fin_text+=' '+text\n",
    "#     tot_no_of_reviews += no_of_reviews\n",
    "# print(tot_no_of_reviews)\n",
    "# chars = tuple(set(fin_text))\n",
    "# int2char = dict(enumerate(chars))\n",
    "# char2int = {ch: ii for ii, ch in int2char.items()}\n",
    "# fortyforty = (int)((max_len_reviews-35)/5)\n",
    "\n",
    "# #print(fortyforty)\n",
    "# max_len_reviews = 36+5*fortyforty\n",
    "# #print(max_len_reviews)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
=======
   "execution_count": 173,
>>>>>>> 3212855949671293fb171a9610f3f23730018b67
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one_hot_encoder(\"o8li\", \"Z&Z~Z&Z~Z&Z~Z&Z~Z&Z~Z&Z~Z&Z~Z&Z~Z&Z~Z&X~\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(synopsis, rev40):\n",
    "#     print(max_len_synop)\n",
    "    encoded = np.array([char2int[ch] for ch in synopsis])\n",
    "    encoded2 = np.array([char2int[ch] for ch in rev40])\n",
    "    ans = np.zeros((max_len_synop+40, len(int2char)), dtype = np.float32)\n",
    "    cnt=max_len_synop-len(synopsis);\n",
    "    for x in encoded:\n",
    "#         print(x)\n",
    "        ans[cnt][x] = 1.0\n",
    "        cnt=cnt+1\n",
    "    for x in encoded2:\n",
    "#         print(x)\n",
    "        ans[cnt][x] = 1.0\n",
    "        cnt=cnt+1\n",
    "    return ans"
=======
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def one_hot_encoder(arr, n_labels):\n",
    "    \n",
    "#     # Initialize the the encoded array\n",
    "#     one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
    "    \n",
    "#     # Fill the appropriate elements with ones\n",
    "#     one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "    \n",
    "#     # Finally reshape it to get back to the original array\n",
    "#     one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "    \n",
    "#     return one_hot"
>>>>>>> 3212855949671293fb171a9610f3f23730018b67
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "one_hot = one_hot_encoder(\"jw3e ???? is smart\")\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
=======
    "def char_encoding2arr(c):\n",
    "    encoded = np.zeros(len(int2char), dtype = np.float32)\n",
    "    encoded[char2int[c]]=1.0\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(1, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "optimizer =optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> 3212855949671293fb171a9610f3f23730018b67
    "def machau(synopsis,review):\n",
    "    fortyforty = (len(review) -36)//5\n",
    "    Y = np.zeros((fortyforty, len(int2char)), dtype=np.float32)\n",
    "    X = np.zeros((fortyforty, 40+max_len_synop, len(int2char)), dtype = np.float32)\n",
    "    for k in range(40, len(review), 5):\n",
    "        l = (int)((k-40)/5)\n",
    "        Y[l] = char_encoding2arr(review[k])\n",
    "        \n",
    "    for i in range(fortyforty):\n",
    "        start_index=i*5;\n",
<<<<<<< HEAD
    "        X[i] = one_hot_encoder(synopsis, review[start_index:start_index+40])\n",
    "print(Y[0])\n",
    "print(X[0])"
=======
    "        temp+=review[start_index:start_index+40]\n",
    "        X[i]=one_hot_encoder(temp)\n",
    "#     print(Y[0])\n",
    "#     print(X[0])"
>>>>>>> 3212855949671293fb171a9610f3f23730018b67
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 1\n",
    "for chunk in pd.read_csv('preprocessed.tsv', chunksize=chunksize, delimiter='\\t'):\n",
    "    df= pd.DataFrame(chunk)\n",
    "    df['reviews'] = df['reviews'].apply(literal_eval)\n",
    "    for review in df.iloc[0]['reviews']:\n",
    "        machau(df.iloc[0]['synopsis'],review)\n",
    "        \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
